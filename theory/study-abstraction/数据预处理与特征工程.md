# 数据的预处理
## 数据清理
- **对各种脏数据进行对应方式的处理，得到标准干净连续的数据，提供给数据统计、数据挖掘等使用**
    - 数据的完整性：例如人的属性中缺少性别、籍贯、年龄等；解决方法是信息补全，使用身份证件号码推算）
    - 数据的唯一性：例如来源不同的数据出现重复的情况；解决方法是按主键去重（用sql或者excel去除重复记录）/按规则去重（如不同渠道来的客户数据可以通过相同的关键信息进行匹配、合并去重
    - 数据的合法性：例如获取数据与常识不符，年龄大于150岁；解决方法是设置字段内容（日期字段为“2006-08-09”）或是类型的合法规则（性别 in[男、女、未知]）
    - 数据的权威性：例如出现多个来源的数据且数值不一样；解决方法是为不同渠道设置权威级别
    - 数据的一致性：例如来源不同的不同指标，实际内涵是一样的，或是同意指标内涵不一致；解决方法是建立数据体系，包含但不限于指标体系、唯独、单位、频度等

## 数据采样
%数据不平衡（imbalance）
- 指数据集的类别分布不均；比如说一个二分类问题 100个训练样本比较理想的情况是正负类样本数量相当，而要是两者差异过大几句意味着存在类不平衡；
- 此时预测时就算全部为正，准确率也可以达到99%，这并不能反映模型的好坏
ps：面临不平衡数据集的时候正统的机器学习模型的评价方法不能精确地衡量模型的性能
%解决方法
- **过采样**（Over-Sampling）通过随机复制少数类来增加其中的实例数量，从而可增加样本中少数类的代表性
- **欠采样**（Under-Sampling）通过随机消除占多数的类的样本来平衡类分布；知道多数类和少数类的实例实现平衡

## 数据集拆分
%机器学习中将数据划分为3份
    1.训练数据集（train dataset）：用来构建机器学习模型
    2.验证数据集（validation dataset）：辅助建构模型，用于在构建过程中评估模型，提供无偏估计，进而调整模型参数
    3.测试数据集（test dataset）：用来评估
    <img width="641" alt="截屏2025-04-10 23 07 54" src="https://github.com/user-attachments/assets/0504941d-ea3b-4ee1-ab60-f611176eee45" />

%常用拆分方法
- 留出法（Hold-Out）：直接将数据集划分为互斥的集合，如通常选择70%数据作为训练集 30%作为测试集，需要注意的是保持划分后集合数据分布的一致性，这样就可以获取k组训练-测试集，从而进行k次训练和测试，k通常取之为10.
- k-折交叉验证法：将数据集划分为k个大小相似的互斥子集并且尽量保证每个子集数据分布的一致性，这样就可以获取k组训练-测试集，从而进行k次训练和测试，k通常取值10
     
# 特征工程
## 特征选择
- 过滤法（Filter）：按照发散性或相关性对个特征进行评分，设定阈值完成特征选择
      - 互信息：指两个随机变量之间的关联程度，即给定一个随机变量后另一个随机变化的确定性；因而互信息取值最小为0，意味着给定一个随机变量对确定一另一随机变量没有关系，越大表示对另一个变量的确定性越高
  
 $$I(X;Y)=\sum \limits_{x\in X} \sum\limits_{y\in Y} p(x,y)log\frac{p(x,y)}{p(x)p(y)}$$ 
 <img width="657" alt="截屏2025-04-11 14 31 16" src="https://github.com/user-attachments/assets/91e3a899-c9d8-4e43-a6bf-2fc5665170e7" />

- 包裹法（Wrapper）：选定特定算法然后通过不断的启发式方法来搜索特征
- 嵌入法（Embedded）：利用正则化的思想，将部分特征属性的权重调整到0，这这个特性相当于就是被舍弃了，常见的正则L1的Lasso，L2Ridge，还有一种综合L1和L2的方法叫Elastic Net

## 特征降维
特征选择完成后可能由于特征矩阵过大导致计算量大、训练时间长，因此降低特征矩阵维度也是必不可少的；
- 主成分分析（PCA）：将原始特征空间映射到彼此正交的特征向量空间 在非满秩的情况下使用SVD分解来构建特征向量
  <img width="566" alt="截屏2025-04-11 14 37 24" src="https://github.com/user-attachments/assets/7440d664-f2a7-43b3-b867-ee1900b2f1ab" />

- 线性判别分析（LDA）：给出一个标注了类别的数据集投影到一条直线后，能够使得点尽量按类别区分开。
<img width="612" alt="截屏2025-04-11 14 38 33" src="https://github.com/user-attachments/assets/e05019c1-696e-4596-a8f3-7f5246d4f06b" />

## 特征编码

 数据集中经常会出现字符串信息，而这些信息不能直接用于算法计算，需要讲这些数据转化为数值形式进行编码，便于后期进行建模。
 <img width="633" alt="截屏2025-04-11 14 41 41" src="https://github.com/user-attachments/assets/8e8b8568-90fd-45af-ac79-61252d40b152" />

 **one-hot 编码**：
 - 图中的elevator和renovation都是定类型数据除去缺失值，Elevator分类有电梯和无电梯两种，因此可用01和10表示；
 - renovation分为有精装、简装，毛胚和其他两种可用0001/0100/0100//1000表示
<img width="441" alt="截屏2025-04-11 14 44 24" src="https://github.com/user-attachments/assets/505f69a8-9308-47b1-85fb-cb883f95b5f3" />

 **语义编码**

 one-hot编码无法提现数据见的语义关系，对于一些有关联的文本信息来说无法真正体现出数据关联
 - 对于这类信息通常采用词嵌入（word embedding）的方式是比较好的选择
 - 目前这一领域比较好的方法是基于google的word2vec方法

## 规范化
不同属性具有不同量级的时候会导致：
    1.数量级的差异将导致量级较大的属性占据主导地位；
    2.数量级的差异将导致迭代手手连速度减慢；
    3.依赖于样本距离的算法对于数据的数量级非常敏感；
    
- **标准化**：通过减去均值然后除以方差或标准差，将数据按比例缩放使之落入一个小的特定区间 $x=(x-\mu)/\sigma$
  适用于：如果数据的分布本身就服从正态分布 就可以用这个方法
- **区间缩放**：将属性缩放到一个指定的最大和最小值（通常是1-0）之间 $x=(x-min)/(max-min)$
- **归一化**：将某个属性特征的模长转化成1.
   $x'=\frac{x}{\sqrt{\sum_j^m x[j]^2}}$ 
