# 数据的预处理
## 数据清理
- **对各种脏数据进行对应方式的处理，得到标准干净连续的数据，提供给数据统计、数据挖掘等使用**
    - 数据的完整性：例如人的属性中缺少性别、籍贯、年龄等；解决方法是信息补全，使用身份证件号码推算）
    - 数据的唯一性：例如来源不同的数据出现重复的情况；解决方法是按主键去重（用sql或者excel去除重复记录）/按规则去重（如不同渠道来的客户数据可以通过相同的关键信息进行匹配、合并去重
    - 数据的合法性：例如获取数据与常识不符，年龄大于150岁；解决方法是设置字段内容（日期字段为“2006-08-09”）或是类型的合法规则（性别 in[男、女、未知]）
    - 数据的权威性：例如出现多个来源的数据且数值不一样；解决方法是为不同渠道设置权威级别
    - 数据的一致性：例如来源不同的不同指标，实际内涵是一样的，或是同意指标内涵不一致；解决方法是建立数据体系，包含但不限于指标体系、唯独、单位、频度等

## 数据采样
%数据不平衡（imbalance）
- 指数据集的类别分布不均；比如说一个二分类问题 100个训练样本比较理想的情况是正负类样本数量相当，而要是两者差异过大几句意味着存在类不平衡；
- 此时预测时就算全部为正，准确率也可以达到99%，这并不能反映模型的好坏
ps：面临不平衡数据集的时候正统的机器学习模型的评价方法不能精确地衡量模型的性能
%解决方法
- **过采样**（Over-Sampling）通过随机复制少数类来增加其中的实例数量，从而可增加样本中少数类的代表性
- **欠采样**（Under-Sampling）通过随机消除占多数的类的样本来平衡类分布；知道多数类和少数类的实例实现平衡

## 数据集拆分
%机器学习中将数据划分为3份
    1.训练数据集（train dataset）：用来构建机器学习模型
    2.验证数据集（validation dataset）：辅助建构模型，用于在构建过程中评估模型，提供无偏估计，进而调整模型参数
    3.测试数据集（test dataset）：用来评估
    <img width="641" alt="截屏2025-04-10 23 07 54" src="https://github.com/user-attachments/assets/0504941d-ea3b-4ee1-ab60-f611176eee45" />
%常用拆分方法
